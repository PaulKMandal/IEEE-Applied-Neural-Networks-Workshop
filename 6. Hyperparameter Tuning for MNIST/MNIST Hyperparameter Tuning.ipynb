{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1ec6e60f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Display an image\n",
    "digit = train_images[4]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 3s 71us/step - loss: 0.2836 - acc: 0.9176 - val_loss: 0.1533 - val_acc: 0.9554\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 3s 66us/step - loss: 0.1167 - acc: 0.9654 - val_loss: 0.1131 - val_acc: 0.9652\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 3s 66us/step - loss: 0.0761 - acc: 0.9771 - val_loss: 0.0880 - val_acc: 0.9723\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 3s 66us/step - loss: 0.0546 - acc: 0.9837 - val_loss: 0.0807 - val_acc: 0.9755\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 3s 66us/step - loss: 0.0406 - acc: 0.9878 - val_loss: 0.0814 - val_acc: 0.9757\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 3s 66us/step - loss: 0.0308 - acc: 0.9909 - val_loss: 0.0823 - val_acc: 0.9777\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0226 - acc: 0.9934 - val_loss: 0.0799 - val_acc: 0.9791\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 3s 69us/step - loss: 0.0168 - acc: 0.9954 - val_loss: 0.0806 - val_acc: 0.9791\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0134 - acc: 0.9963 - val_loss: 0.0951 - val_acc: 0.9751\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 3s 65us/step - loss: 0.0100 - acc: 0.9973 - val_loss: 0.0828 - val_acc: 0.9796\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation = 'relu', input_shape = (28 * 28,)))\n",
    "network.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "network.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "hist1 = network.fit(train_images, train_labels, epochs=10, batch_size = 128, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.5520 - acc: 0.8571 - val_loss: 0.3064 - val_acc: 0.9142\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 1s 18us/step - loss: 0.2951 - acc: 0.9165 - val_loss: 0.2593 - val_acc: 0.9288\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 1s 18us/step - loss: 0.2565 - acc: 0.9276 - val_loss: 0.2399 - val_acc: 0.9335\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 1s 18us/step - loss: 0.2310 - acc: 0.9349 - val_loss: 0.2160 - val_acc: 0.9418\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 1s 18us/step - loss: 0.2106 - acc: 0.9405 - val_loss: 0.2063 - val_acc: 0.9442\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 1s 18us/step - loss: 0.1942 - acc: 0.9452 - val_loss: 0.1935 - val_acc: 0.9485\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 1s 18us/step - loss: 0.1793 - acc: 0.9493 - val_loss: 0.1840 - val_acc: 0.9487\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.1680 - acc: 0.9526 - val_loss: 0.1764 - val_acc: 0.9515\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 1s 17us/step - loss: 0.1580 - acc: 0.9558 - val_loss: 0.1682 - val_acc: 0.9535\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 1s 18us/step - loss: 0.1496 - acc: 0.9575 - val_loss: 0.1658 - val_acc: 0.9528\n"
     ]
    }
   ],
   "source": [
    "#Now for a second network\n",
    "network2 = models.Sequential()\n",
    "network2.add(layers.Dense(25, activation = 'relu', input_shape = (28 * 28,)))\n",
    "network2.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "network2.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "hist2 = network2.fit(train_images, train_labels, epochs=10, batch_size = 128, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1f0605320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1,11)\n",
    "m1_val_loss = hist1.history['val_loss']\n",
    "m2_val_loss = hist2.history['val_loss']\n",
    "\n",
    "# b+ is for \"blue cross\"\n",
    "plt.plot(epochs, m1_val_loss, 'b+', label='Model 1')\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, m2_val_loss, 'bo', label='Model 2')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 3s 70us/step - loss: 0.2873 - acc: 0.9157 - val_loss: 0.1472 - val_acc: 0.9572\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 3s 66us/step - loss: 0.1174 - acc: 0.9653 - val_loss: 0.1070 - val_acc: 0.9678\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 3s 66us/step - loss: 0.0763 - acc: 0.9774 - val_loss: 0.0951 - val_acc: 0.9720\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 3s 66us/step - loss: 0.0553 - acc: 0.9832 - val_loss: 0.0889 - val_acc: 0.9737\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 3s 66us/step - loss: 0.0414 - acc: 0.9878 - val_loss: 0.0840 - val_acc: 0.9767\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 0.0305 - acc: 0.9912 - val_loss: 0.0811 - val_acc: 0.9778\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 3s 71us/step - loss: 0.0238 - acc: 0.9930 - val_loss: 0.0962 - val_acc: 0.9744\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 3s 72us/step - loss: 0.0177 - acc: 0.9948 - val_loss: 0.0882 - val_acc: 0.9753\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 3s 71us/step - loss: 0.0137 - acc: 0.9964 - val_loss: 0.0809 - val_acc: 0.9791\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 3s 72us/step - loss: 0.0100 - acc: 0.9974 - val_loss: 0.0862 - val_acc: 0.9788\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 3s 72us/step - loss: 0.0076 - acc: 0.9980 - val_loss: 0.0859 - val_acc: 0.9807\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 4s 73us/step - loss: 0.0063 - acc: 0.9984 - val_loss: 0.0837 - val_acc: 0.9813\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 3s 73us/step - loss: 0.0044 - acc: 0.9990 - val_loss: 0.0890 - val_acc: 0.9808\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 3s 73us/step - loss: 0.0037 - acc: 0.9990 - val_loss: 0.0942 - val_acc: 0.9803\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 3s 71us/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0967 - val_acc: 0.9804\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0989 - val_acc: 0.9808\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.1046 - val_acc: 0.9798\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.1073 - val_acc: 0.9802\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 7.4153e-04 - acc: 0.9999 - val_loss: 0.1179 - val_acc: 0.9790\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 9.8112e-04 - acc: 0.9998 - val_loss: 0.1111 - val_acc: 0.9809\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 3s 69us/step - loss: 6.0573e-04 - acc: 0.9998 - val_loss: 0.1123 - val_acc: 0.9801\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 3s 69us/step - loss: 5.9821e-04 - acc: 0.9998 - val_loss: 0.1154 - val_acc: 0.9797\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 3s 70us/step - loss: 4.8508e-04 - acc: 0.9999 - val_loss: 0.1167 - val_acc: 0.9802\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 2.4890e-04 - acc: 1.0000 - val_loss: 0.1253 - val_acc: 0.9797\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 3s 69us/step - loss: 4.2698e-04 - acc: 0.9998 - val_loss: 0.1211 - val_acc: 0.9802\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 3.2821e-04 - acc: 0.9999 - val_loss: 0.1192 - val_acc: 0.9800\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 1.6809e-04 - acc: 1.0000 - val_loss: 0.1259 - val_acc: 0.9809\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 3s 69us/step - loss: 1.2357e-04 - acc: 1.0000 - val_loss: 0.1360 - val_acc: 0.9793\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 2.4882e-04 - acc: 0.9999 - val_loss: 0.1247 - val_acc: 0.9807\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 7.2182e-05 - acc: 1.0000 - val_loss: 0.1343 - val_acc: 0.9803\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 3s 69us/step - loss: 5.9309e-05 - acc: 1.0000 - val_loss: 0.1293 - val_acc: 0.9804\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 1.0585e-04 - acc: 1.0000 - val_loss: 0.1399 - val_acc: 0.9802\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 1.5129e-04 - acc: 1.0000 - val_loss: 0.1405 - val_acc: 0.9790\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 3s 69us/step - loss: 2.4221e-05 - acc: 1.0000 - val_loss: 0.1373 - val_acc: 0.9797\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 3.5256e-05 - acc: 1.0000 - val_loss: 0.1333 - val_acc: 0.9805\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 3s 69us/step - loss: 4.0758e-05 - acc: 1.0000 - val_loss: 0.1364 - val_acc: 0.9813\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 3s 69us/step - loss: 8.2236e-06 - acc: 1.0000 - val_loss: 0.1344 - val_acc: 0.9806\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 7.3765e-06 - acc: 1.0000 - val_loss: 0.1356 - val_acc: 0.9808\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 3s 70us/step - loss: 8.6361e-06 - acc: 1.0000 - val_loss: 0.1393 - val_acc: 0.9810\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 3s 69us/step - loss: 5.1077e-06 - acc: 1.0000 - val_loss: 0.1425 - val_acc: 0.9802\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 1.0411e-06 - acc: 1.0000 - val_loss: 0.1383 - val_acc: 0.9807\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 2.0908e-07 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.9807\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 1.6131e-07 - acc: 1.0000 - val_loss: 0.1385 - val_acc: 0.9814\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 1.4852e-07 - acc: 1.0000 - val_loss: 0.1390 - val_acc: 0.9811\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 3s 66us/step - loss: 1.4194e-07 - acc: 1.0000 - val_loss: 0.1395 - val_acc: 0.9814\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 1.3845e-07 - acc: 1.0000 - val_loss: 0.1394 - val_acc: 0.9810\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 1.3577e-07 - acc: 1.0000 - val_loss: 0.1397 - val_acc: 0.9813\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 1.3366e-07 - acc: 1.0000 - val_loss: 0.1399 - val_acc: 0.9812\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 1.3240e-07 - acc: 1.0000 - val_loss: 0.1402 - val_acc: 0.9812\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 1.3083e-07 - acc: 1.0000 - val_loss: 0.1409 - val_acc: 0.9812\n"
     ]
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation = 'relu', input_shape = (28 * 28,)))\n",
    "network.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "network.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "hist1 = network.fit(train_images, train_labels, epochs=50, batch_size = 128, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.6121 - acc: 0.8911 - val_loss: 0.3463 - val_acc: 0.9473\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.3379 - acc: 0.9392 - val_loss: 0.2468 - val_acc: 0.9614\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.2748 - acc: 0.9487 - val_loss: 0.2131 - val_acc: 0.9646\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.2473 - acc: 0.9521 - val_loss: 0.2007 - val_acc: 0.9657\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 4s 82us/step - loss: 0.2314 - acc: 0.9556 - val_loss: 0.2043 - val_acc: 0.9648\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.2239 - acc: 0.9558 - val_loss: 0.1927 - val_acc: 0.9653\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.2148 - acc: 0.9593 - val_loss: 0.1813 - val_acc: 0.9715\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 4s 82us/step - loss: 0.2100 - acc: 0.9600 - val_loss: 0.1792 - val_acc: 0.9693\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 4s 82us/step - loss: 0.2077 - acc: 0.9599 - val_loss: 0.1694 - val_acc: 0.9719\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 4s 82us/step - loss: 0.2056 - acc: 0.9599 - val_loss: 0.1883 - val_acc: 0.9646\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 4s 82us/step - loss: 0.2014 - acc: 0.9622 - val_loss: 0.1692 - val_acc: 0.9716\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 4s 82us/step - loss: 0.2015 - acc: 0.9604 - val_loss: 0.1689 - val_acc: 0.9718\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 4s 82us/step - loss: 0.1969 - acc: 0.9622 - val_loss: 0.1703 - val_acc: 0.9701\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.2015 - acc: 0.9610 - val_loss: 0.1758 - val_acc: 0.9681\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1953 - acc: 0.9621 - val_loss: 0.1695 - val_acc: 0.9695\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 4s 82us/step - loss: 0.1968 - acc: 0.9622 - val_loss: 0.1579 - val_acc: 0.9741\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 4s 82us/step - loss: 0.1971 - acc: 0.9612 - val_loss: 0.1687 - val_acc: 0.9699\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 4s 82us/step - loss: 0.1933 - acc: 0.9624 - val_loss: 0.1635 - val_acc: 0.9731\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 4s 82us/step - loss: 0.1938 - acc: 0.9624 - val_loss: 0.1748 - val_acc: 0.9702\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 4s 82us/step - loss: 0.1920 - acc: 0.9634 - val_loss: 0.1649 - val_acc: 0.9709\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1939 - acc: 0.9625 - val_loss: 0.1686 - val_acc: 0.9716\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1926 - acc: 0.9625 - val_loss: 0.1570 - val_acc: 0.9742\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1918 - acc: 0.9628 - val_loss: 0.1698 - val_acc: 0.9721\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.1915 - acc: 0.9630 - val_loss: 0.1560 - val_acc: 0.9752\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 4s 85us/step - loss: 0.1893 - acc: 0.9635 - val_loss: 0.1623 - val_acc: 0.9736\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1904 - acc: 0.9636 - val_loss: 0.1685 - val_acc: 0.9714\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1915 - acc: 0.9626 - val_loss: 0.1590 - val_acc: 0.9741\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.1920 - acc: 0.9628 - val_loss: 0.1571 - val_acc: 0.9742\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.1904 - acc: 0.9622 - val_loss: 0.1523 - val_acc: 0.9755\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1867 - acc: 0.9646 - val_loss: 0.1572 - val_acc: 0.9743\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.1913 - acc: 0.9634 - val_loss: 0.1666 - val_acc: 0.9712\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.1862 - acc: 0.9635 - val_loss: 0.1541 - val_acc: 0.9751\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.1906 - acc: 0.9626 - val_loss: 0.1622 - val_acc: 0.9726\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.1873 - acc: 0.9636 - val_loss: 0.1652 - val_acc: 0.9718\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1918 - acc: 0.9631 - val_loss: 0.1555 - val_acc: 0.9751\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 4s 86us/step - loss: 0.1889 - acc: 0.9633 - val_loss: 0.1501 - val_acc: 0.9762\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1889 - acc: 0.9628 - val_loss: 0.1536 - val_acc: 0.9742\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1883 - acc: 0.9632 - val_loss: 0.1553 - val_acc: 0.9745\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 4s 82us/step - loss: 0.1887 - acc: 0.9634 - val_loss: 0.1551 - val_acc: 0.9738\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1887 - acc: 0.9638 - val_loss: 0.1687 - val_acc: 0.9711\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1893 - acc: 0.9629 - val_loss: 0.1762 - val_acc: 0.9678\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1905 - acc: 0.9630 - val_loss: 0.1545 - val_acc: 0.9733\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1898 - acc: 0.9625 - val_loss: 0.1572 - val_acc: 0.9732\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1895 - acc: 0.9628 - val_loss: 0.1548 - val_acc: 0.9739\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1879 - acc: 0.9630 - val_loss: 0.1611 - val_acc: 0.9732\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1891 - acc: 0.9632 - val_loss: 0.1566 - val_acc: 0.9739\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1874 - acc: 0.9636 - val_loss: 0.1555 - val_acc: 0.9760\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.1888 - acc: 0.9641 - val_loss: 0.1486 - val_acc: 0.9763\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 4s 85us/step - loss: 0.1859 - acc: 0.9637 - val_loss: 0.1672 - val_acc: 0.9710\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1892 - acc: 0.9632 - val_loss: 0.1531 - val_acc: 0.9753\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "network3 = models.Sequential()\n",
    "network3.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001), activation = 'relu', input_shape = (28 * 28,)))\n",
    "network3.add(layers.Dropout(0.5))\n",
    "network3.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "network3.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "hist3 = network3.fit(train_images, train_labels, epochs=50, batch_size = 128, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
